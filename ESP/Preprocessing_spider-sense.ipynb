{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento --= Spider-sense =--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos para correlação de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas e módulos para o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando arquivo como variável array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spider_sense = pd.read_csv(\"datasets/Spider-sense_3k_samples.csv\")\n",
    "np_spider_sense = df_spider_sense.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Exploratória de Dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando os dados\n",
    "print(df_spider_sense.shape, \"\\n\")\n",
    "print(df_spider_sense.head(1), \"\\n\")\n",
    "#print(df_spider_sense.columns, \"\\n\")\n",
    "print(df_spider_sense.describe(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando graficamente os dados\n",
    "df_spider_sense.iloc[:, 11:20].hist(bins=50, figsize=(12,8))\n",
    "#Para ajustar os títulos e rótulos de cada eixo (se houver)\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "    ax.title.set_fontsize(8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmos de correlação de atributos\n",
    "\n",
    "- Pearson Correlation (atributos numéricos):  \n",
    "\n",
    "    Encontra o relacionamento linear dos atributos ideal para classificação binária (0_1, A_B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecionando as colunas de atributos (amplitudes)\n",
    "atributos = df_spider_sense.iloc[:, 11:61]\n",
    "\n",
    "#Selecionando a coluna alvo ('rotulo')\n",
    "rotulo = df_spider_sense.iloc[:, 113].map({\"falha\": 0, \"sucesso\": 1})\n",
    "\n",
    "# Concatenando atributos + alvo\n",
    "df_corr = pd.concat([atributos, rotulo.rename(\"rotulo\")], axis=1)\n",
    "\n",
    "#Calculando correlação de Pearson entre cada atributo e a classe alvo ('rotulo')\n",
    "correlations = df_corr.corr(method='pearson')['rotulo'].drop('rotulo')\n",
    "\n",
    "#Top 9 maiores correlações positivas e negativas\n",
    "top9_pos = correlations.sort_values(key=abs, ascending=False).head(9)\n",
    "#top9_neg = correlations.sort_values(key=abs, ascending=True).head(9)\n",
    "\n",
    "print(\"Correlação de Pearson entre atributos e classe alvo:\")\n",
    "print(\"Top 9 atributos mais positivamente correlacionados com 'rotulo':\", '\\n', top9_pos, '\\n',)\n",
    "#print(\"Top 9 atributos mais negativamente correlacionados com 'rotulo':\", '\\n', top9_neg)\n",
    "\n",
    "#Selecionando os atributos mais correlacionados com classe alvo ('rotulo')\n",
    "att_pearson_corr = top9_pos.index.tolist() #+ top9_neg.index.tolist()\n",
    "print(att_pearson_corr)\n",
    "\n",
    "#===============================================\n",
    "#Plotando as 9 maiores correlações positivas\n",
    "plt.figure(figsize=(6,3))\n",
    "top9_pos.plot(kind='barh', color='green', alpha=0.7, label=\"Positiva\")\n",
    "\n",
    "#Plotando as 9 maiores correlações negativas\n",
    "#top9_neg.plot(kind='barh', color='red', alpha=0.7, label=\"Negativa\")\n",
    "\n",
    "plt.title(\"Top atributos correlacionados\", fontsize=14)\n",
    "plt.ylabel(\"Coeficiente de Correlação (Pearson)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest (atributos numéricos):  \n",
    "\n",
    "    Encontra relações complexas e não-lineares entre o astributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparação dos dados (é necessário para o algoritmo Random Forest)\n",
    "X = df_corr.drop(columns=['rotulo'])      #Apenas atributos sem classe alvo\n",
    "y = df_corr['rotulo']                     #Classe alvo\n",
    "\n",
    "#Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#======================\n",
    "#Modelo Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=235,        #número de árvores\n",
    "    max_depth=20,            #profundidade ilimitada\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#Ordenação dos atributos pela importância\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "importances_sorted = importances.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nImportância dos atributos segundo o Random Forest:\")\n",
    "print(importances_sorted.head(9))  #mostra os 9 mais importantes\n",
    "\n",
    "att_RF_corr = importances_sorted.head(9).index.tolist()\n",
    "print(att_RF_corr)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "importances_sorted.head(9).plot(kind='barh')\n",
    "plt.title(\"Top 9 atributos mais importantes (Random Forest)\", fontsize=14)\n",
    "plt.ylabel(\"Importância (Gini Importance)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atributos com grande correlação com a classe alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_att = []\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        if att_pearson_corr[i] == att_RF_corr[j]:\n",
    "            best_att.append(att_pearson_corr[i])\n",
    "            \n",
    "\n",
    "print(best_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PairPlot da distribuição dos melhores atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um novo DataFrame contendo os melhores atributos e a coluna de 'rotulo'\n",
    "df_plot = df_corr[best_att + ['rotulo']].copy()\n",
    "\n",
    "#Renomear a coluna e mapear os valores para falha = 0, sucesso = 1\n",
    "df_plot = df_plot.rename(columns={'rotulo': 'Rotulo'})\n",
    "df_plot['Rotulo'] = df_plot['Rotulo'].map({0: 'falha', 1: 'sucesso'})\n",
    "\n",
    "print(df_plot.head())\n",
    "\n",
    "#Cria um gráfico de dispersão múltipla entre entre os atributos e a classe alvo\n",
    "plot = sns.pairplot(df_plot, hue='Rotulo', hue_order=['falha', 'sucesso'], palette='Set1', corner=True, height=1.3, aspect=1.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizando a Função de Distribuição Cumulativa (CDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para calcular CDF empírica\n",
    "def ecdf(data):\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, len(x)+1) / len(x)\n",
    "    return x, y\n",
    "\n",
    "#Criando grid de subplots (2 linhas × 3 colunas)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "#Plotando CDF para os melhores atributos (best_att)\n",
    "for i, col in enumerate(best_att):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    #Dados separados por rótulo\n",
    "    dados_falha = df_corr[df_corr['rotulo'] == 0][col]\n",
    "    dados_sucesso = df_corr[df_corr['rotulo'] == 1][col]\n",
    "    \n",
    "    #Calcula CDF para falha\n",
    "    x_f, y_f = ecdf(dados_falha)\n",
    "    ax.plot(x_f, y_f, label=\"Falha (0)\", color=\"red\", alpha=0.7)\n",
    "    \n",
    "    #Calcula CDF para sucesso\n",
    "    x_s, y_s = ecdf(dados_sucesso)\n",
    "    ax.plot(x_s, y_s, label=\"Sucesso (1)\", color=\"green\", alpha=0.7)\n",
    "    \n",
    "    #Ajustes do gráfico\n",
    "    ax.set_title(f\"CDF - {col}\", fontsize=12)\n",
    "    ax.set_xlabel(\"Valor do atributo\")\n",
    "    ax.set_ylabel(\"Probabilidade acumulada\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas e módulos para o treinamento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmos de Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier                      #Árvores de decisão\n",
    "from sklearn.neighbors import KNeighborsClassifier                   #kNN\n",
    "from sklearn.naive_bayes import GaussianNB                           #Naive Bayes\n",
    "from sklearn.svm import LinearSVC                                    #Máquinas de Vetores de Suporte\n",
    "from sklearn.linear_model import SGDClassifier                       #Gradiente Estocástico\n",
    "import joblib                                                        #Salvamento e carregamento de modelos\n",
    "\n",
    "#Utilidades\n",
    "from sklearn.preprocessing import StandardScaler                     #Normalização de atributos\n",
    "import time                                                          #Tempo de execução\n",
    "from pathlib import Path                                             #Caminhos de arquivos\n",
    "\n",
    "#Avaliação e seleção de modelos\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,                                                #Validação cruzada simples\n",
    "    StratifiedKFold,                                                #Validação estratificada\n",
    "    GridSearchCV,                                                   #Busca em grade de hiperparâmetros\n",
    ")\n",
    "\n",
    "#Métricas de avaliação\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,        #Métricas principais\n",
    "    confusion_matrix, classification_report, ConfusionMatrixDisplay #Relatórios e matrizes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparado conjunto de dados CSI para treinamento dos algoritmos de *Machine Learning*\n",
    "\n",
    "Total: 3.000 amostras de 1.500 tentativas (falha) e 1.500 autenticações (sucesso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construção de dados de treinamento e teste (Foram retirados 2 individuos de cada classe - 20% dos dados)\n",
    "df_spider_sense = pd.read_csv(\"datasets/Spider-sense_3k_samples.csv\")\n",
    "\n",
    "#Selecionar apenas os atributos mais correlacionados com a classe alvo \n",
    "df_spider_sense_selected = df_spider_sense[best_att + ['rotulo']]\n",
    "\n",
    "print(df_spider_sense_selected.head(), '\\n')\n",
    "\n",
    "#Preparação dos dados\n",
    "X = df_spider_sense_selected.drop(columns=['rotulo'])      #Apenas atributos sem classe alvo\n",
    "y = df_spider_sense_selected['rotulo']                     #Classe alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com validação cruzada\n",
    "\n",
    "- Padronização dos dados usando Z-score (pelo StandardScaler)\n",
    "- Seleção dos melhores hiperparâmetros para cada algoritmo (pelo GridSearchCV)\n",
    "- Treinamento usando a validação cruzada e a seleção do melhor modelo para cada algoritmo (pelo StratifieldKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padronização dos dados CSI com média=0 e desvio_padrão=1 (Z-score)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Definindo os modelos e hiperparâmetros\n",
    "modelos_com_grid = {\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(random_state=42), {\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }),\n",
    "    \"kNN\": (KNeighborsClassifier(), {\n",
    "        'n_neighbors': [3, 5, 7]\n",
    "    }),\n",
    "    \"Naive Bayes\": (GaussianNB(), {}),\n",
    "    \"SVM Linear\": (LinearSVC(random_state=42, dual=False, max_iter=10000), {\n",
    "        'C': [0.1, 1, 10]\n",
    "    })\n",
    "}\n",
    "\n",
    "#Definindo as validações (configuração nested CV)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "#Avaliação de modelos\n",
    "resultados_val = {}\n",
    "melhor_modelo = None\n",
    "melhor_nome = \"\"\n",
    "melhor_acc = 0\n",
    "\n",
    "output_dir = Path(\"results/cross-validation\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "relatorio_path = output_dir / \"relatorio.txt\"\n",
    "\n",
    "with open(relatorio_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Relatório da Validação Cruzada:\\n\\n\")\n",
    "\n",
    "    for nome, (modelo, grid) in modelos_com_grid.items():\n",
    "        print(f\"\\nModel: {nome}\")\n",
    "\n",
    "        #Caso haja grid, usar GridSearchCV\n",
    "        if grid:\n",
    "            grid_search = GridSearchCV(modelo, grid, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "        else:\n",
    "            grid_search = modelo\n",
    "\n",
    "        #Validação cruzada\n",
    "        scores = cross_val_score(grid_search, X=X_scaled, y=y, cv=outer_cv, n_jobs=-1)\n",
    "        resultados_val[nome] = scores\n",
    "\n",
    "        #Treino final (melhor modelo) e medição de tempo\n",
    "        start = time.perf_counter()\n",
    "        grid_search.fit(X_scaled, y)\n",
    "        end = time.perf_counter()\n",
    "        tempo_treino = end - start\n",
    "\n",
    "        final_model = grid_search.best_estimator_ if hasattr(grid_search, 'best_estimator_') else grid_search\n",
    "\n",
    "        #Predição e avaliação do melhor modelo\n",
    "        y_pred = final_model.predict(X_scaled)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "\n",
    "        #Relatório\n",
    "        relatorio = classification_report(y, y_pred, target_names=[\"falha\", \"sucesso\"], digits=4)\n",
    "        f.write(f\"Model: {nome}\\n\")\n",
    "        f.write(f\"Tempo de construção: {tempo_treino:.6f} segundos\\n\")\n",
    "        f.write(relatorio)\n",
    "        f.write(\"\\n\" + \"-\" * 60 + \"\\n\")\n",
    "\n",
    "        print(relatorio)\n",
    "        print(f\"Tempo de construção do modelo: {tempo_treino:.6f} segundos\")\n",
    "\n",
    "        #Atualização do melhor modelo\n",
    "        if acc > melhor_acc:\n",
    "            melhor_acc = acc\n",
    "            melhor_modelo = final_model\n",
    "            melhor_nome = nome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusão do melhor classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predição com o melhor modelo encontrado\n",
    "y_pred_final = melhor_modelo.predict(X_scaled)\n",
    "\n",
    "#Matriz de confusão\n",
    "cm = confusion_matrix(y, y_pred_final)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Falha (0)\", \"Sucesso (1)\"])\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(f\"Matriz de Confusão - {melhor_nome}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
